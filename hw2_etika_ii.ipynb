{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Этика ИИ\n",
    "## Итоговый проект. Николаев А.М."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка необходимых библиотек и датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21695</th>\n",
       "      <td>5204917</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>flagged for your antisemite stupidity and hate...</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>331259</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44235</th>\n",
       "      <td>6276191</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>But did he have any attack chickens?\\nSaw a po...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>396013</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5080</th>\n",
       "      <td>491603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Christopher, history reminds us that you can't...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>146784</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45481</th>\n",
       "      <td>5598527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>No need to have over paid technicians like Kyl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>355689</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84883</th>\n",
       "      <td>5783856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>You have a point.  Low time pilots and Alaskan...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>367051</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66219</th>\n",
       "      <td>1007323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>\"Many Canadians too cash-strapped to raise chi...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>168445</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15131</th>\n",
       "      <td>965886</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>You mean the Liberals should do what the Conse...</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>166795</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23685</th>\n",
       "      <td>5304574</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>Another commenter with zero credibility. \\nYou...</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>337266</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18292</th>\n",
       "      <td>5026061</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>ignorance never ends from you left wingers</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>320575</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52948</th>\n",
       "      <td>5929873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Pray all you want Skeletor, prayer and a nicke...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>376212</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    target                                       comment_text  \\\n",
       "21695  5204917  0.904762  flagged for your antisemite stupidity and hate...   \n",
       "44235  6276191  1.000000  But did he have any attack chickens?\\nSaw a po...   \n",
       "5080    491603  1.000000  Christopher, history reminds us that you can't...   \n",
       "45481  5598527  0.000000  No need to have over paid technicians like Kyl...   \n",
       "84883  5783856  0.000000  You have a point.  Low time pilots and Alaskan...   \n",
       "66219  1007323  0.000000  \"Many Canadians too cash-strapped to raise chi...   \n",
       "15131   965886  0.774194  You mean the Liberals should do what the Conse...   \n",
       "23685  5304574  0.843750  Another commenter with zero credibility. \\nYou...   \n",
       "18292  5026061  0.800000         ignorance never ends from you left wingers   \n",
       "52948  5929873  0.000000  Pray all you want Skeletor, prayer and a nicke...   \n",
       "\n",
       "       severe_toxicity   obscene  identity_attack    insult  threat  asian  \\\n",
       "21695         0.023810  0.142857         0.166667  0.857143     0.0    0.0   \n",
       "44235         0.000000  0.000000         0.000000  1.000000     0.0    0.0   \n",
       "5080          0.000000  0.000000         1.000000  0.000000     0.0    0.0   \n",
       "45481         0.000000  0.000000         0.000000  0.000000     0.0    NaN   \n",
       "84883         0.000000  0.000000         0.000000  0.000000     0.0    NaN   \n",
       "66219         0.000000  0.000000         0.000000  0.000000     0.0    NaN   \n",
       "15131         0.048387  0.290323         0.016129  0.725806     0.0    NaN   \n",
       "23685         0.046875  0.140625         0.015625  0.859375     0.0    NaN   \n",
       "18292         0.000000  0.000000         0.000000  0.800000     0.0    NaN   \n",
       "52948         0.000000  0.000000         0.000000  0.000000     0.0    NaN   \n",
       "\n",
       "       atheist  ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "21695      0.0  ...      331259  rejected      0    0    0      0         0   \n",
       "44235      0.0  ...      396013  approved      0    0    0      2         0   \n",
       "5080       0.0  ...      146784  approved      0    0    0      1         0   \n",
       "45481      NaN  ...      355689  approved      1    0    0      4         0   \n",
       "84883      NaN  ...      367051  approved      0    0    0      1         0   \n",
       "66219      NaN  ...      168445  approved      0    0    0      3         2   \n",
       "15131      NaN  ...      166795  rejected      0    0    0      0         0   \n",
       "23685      NaN  ...      337266  approved      0    0    0      2         1   \n",
       "18292      NaN  ...      320575  rejected      0    0    0      3         3   \n",
       "52948      NaN  ...      376212  approved      0    0    0      0         0   \n",
       "\n",
       "       sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "21695              0.0                         5                        42  \n",
       "44235              0.0                         4                         4  \n",
       "5080               0.0                        10                         4  \n",
       "45481              0.0                         0                         4  \n",
       "84883              0.0                         0                         4  \n",
       "66219              0.0                         0                         4  \n",
       "15131              0.0                         0                        62  \n",
       "23685              0.0                         0                        64  \n",
       "18292              0.0                         0                         5  \n",
       "52948              0.0                         0                         4  \n",
       "\n",
       "[10 rows x 45 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r'C:\\Users\\User\\Desktop\\etika_ii\\data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача\n",
    "В конце 2017 года платформа Civil Comments закрылась и опубликовала около 2 миллионов комментариев из социальных сетей, чтобы специалисты по данным со всего мира могли работать вместе над исследованием способов смягчения предвзятости в текстовых данных.\n",
    "\n",
    "Таблица с комментариями также прилагается: data.csv. Мы будем работать с тысячами комментариев, где каждый комментарий помечен как «токсичный» или «нетоксичный».\n",
    "\n",
    "В таблице data.csv в колонке comment_text написаны сами комментарии, с которыми нам предстоит работать. В колонке target стоят вероятности того, что комментарий токсичен. Давайте сделаем предпосылку, что комментарий считается токсичным, если вероятность выше 0.7.\n",
    "\n",
    "Выполните код ниже, чтобы отделить колонки и преобразовать вероятности в бинарные величины, где 1 — токсичный комментарий, а 0 — нетоксичный комментарий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21886    Women in their 30's without children are usual...\n",
      "56873    2/2\\nI suspect you've never read a word Bernar...\n",
      "56515    AKHunter, I was just looking at the Wood-Tickc...\n",
      "26096                    Darn, all those onions again ....\n",
      "37812    Wow Exedus, you are working this thread on OT....\n",
      "29497    What an idiot. Your saying retired people are ...\n",
      "60634    Golfing? Likely! In day 202 of his presidency,...\n",
      "9463     Ontario elected a School Teacher,so why is any...\n",
      "38441    What the f are you talking about?  Is this sar...\n",
      "52298    My wife found a home with a fully assumable 16...\n",
      "Name: comment_text, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74524    0\n",
       "53719    0\n",
       "505      1\n",
       "6412     1\n",
       "33358    1\n",
       "54937    0\n",
       "86877    0\n",
       "63543    0\n",
       "40383    1\n",
       "42607    1\n",
       "Name: binary_target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['binary_target'] = (data['target'] > 0.7).astype(int)\n",
    "\n",
    "comments = data['comment_text']\n",
    "target = data['binary_target']\n",
    "\n",
    "print(comments.sample(10))\n",
    "target.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1\n",
    "\n",
    "Теперь разделим наши данные на train и test. Пусть в тест у нас пойдет 30% данных. Для этого можете использовать библиотеку train_test_split из sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63631 27271 63631 27271\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(comments, target, test_size=0.3, random_state=0)\n",
    "\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 2\n",
    "\n",
    "Как вы уже, наверное, догадались, в наших данных есть определенная проблема — это разные типы данных. Предсказывать мы хотим бинарную величину: 1 и 0. А на вход мы подаем текст, а не числа. Поэтому нам нужно как-то сконвертировать текст в число.\n",
    "\n",
    "Давайте это сделаем!\n",
    "\n",
    "Вам понадобится функция CountVectorizer: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "Преобразуйте текст, который вы поделили на train и test, в числовой формат с помощью этой функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((63631, 58152), (27271, 58152))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "X_train_vectorized.shape, X_test_vectorized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 3\n",
    "\n",
    "Теперь в качестве модели, которая будет классифицировать нам комментарии на токсичные и нетоксичные, возьмем логистическую регрессию.\n",
    "\n",
    "Импортируйте из библиотеки sklearn логистическую регрессию LogisticRegression с параметром max_iter=2000. Для оценки модели возьмите метрику accuracy и посчитайте ее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9287154853140699"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(max_iter=2000, random_state=0)\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 4\n",
    "\n",
    "Чтобы мы смогли протестировать разные комментарии, которые приходят в голову, пропишите ниже функцию, для которой на вход мы бы подавали наш комментарий, а на выход получали предсказание, насколько от 0 до 1 комментарий является токсичным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_toxicity(com, vectorizer, classifier):\n",
    "\n",
    "    vectorized_comment = vectorizer.transform([com])\n",
    "    probability = classifier.predict_proba(vectorized_comment)[0, 1]\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 5\n",
    "\n",
    "Поздравляю! Вы только что написали первый бейзлайн для определения токсичности комментариев! :)\n",
    "\n",
    "А теперь посмотрим, насколько он этичен.\n",
    "\n",
    "Попробуйте предсказать, токсичен ли комментарий «Apples are stupid». Потом предскажите, токсичен ли комментарий «I love apples»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Apples are stupid' - токсичность: 1.00\n",
      "'I love apples' - токсичность: 0.10\n"
     ]
    }
   ],
   "source": [
    "com1 = \"Apples are stupid\"\n",
    "com2 = \"I love apples\"\n",
    "\n",
    "toxicity1 = predict_toxicity(com1, vectorizer, classifier)\n",
    "toxicity2 = predict_toxicity(com2, vectorizer, classifier)\n",
    "\n",
    "print(f\"'{com1}' - токсичность: {toxicity1:.2f}\")\n",
    "print(f\"'{com2}' - токсичность: {toxicity2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 6\n",
    "\n",
    "Если ваш алгоритм работает корректно, то комментарий «I love apples» должен быть определен как нетоксичный, а «Apples are stupid» — как токсичный.\n",
    "\n",
    "А теперь перейдем к пониманию того, как модель принимает решения: модель присваивает каждому из примерно 58 000 слов коэффициент, причем более высокие коэффициенты обозначают слова, которые модель считает более токсичными. Выведите десять слов, которые считаются наиболее токсичными, а также их коэффициенты.\n",
    "\n",
    "Hint: в этом вам поможет атрибут vectorizer.vocabulary_.keys() и classifier.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stupid: 9.4708\n",
      "idiot: 8.6652\n",
      "idiots: 8.6195\n",
      "stupidity: 7.5686\n",
      "idiotic: 6.7927\n",
      "crap: 6.5523\n",
      "dumb: 6.5368\n",
      "pathetic: 6.4536\n",
      "morons: 6.3361\n",
      "moron: 6.3253\n"
     ]
    }
   ],
   "source": [
    "word_coefs = list(zip(vectorizer.get_feature_names_out(), classifier.coef_[0]))\n",
    "sorted_words = sorted(word_coefs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "top_toxic_words = sorted_words[:10]\n",
    "for word, coef in top_toxic_words:\n",
    "    print(f\"{word}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 7\n",
    "\n",
    "Взгляните на самые токсичные слова из задания 6. Вызывают ли у вас удивление какие-нибудь из них? Есть ли слова, которых, кажется, не должно быть в списке?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом удивления не вызывает, скорее разочаровывает, что почти все слова связаны с оценкой интеллектуальных способностей, я ожидал более ярких ругательств UwU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 8\n",
    "\n",
    "Давайте попробуем протестировать модель на ее предвзятость, например, к религии.\n",
    "\n",
    "Примечание: DISCLAIMER мы обсуждали это на лекциях и семинарах, но повторим еще раз: наша задача — отследить предвзятость алгоритма, а не обидеть или оскорбить представителей определенной национальности, религии, политических кругов и т.д.\n",
    "Давайте посмотрим, как ваш алгоритм классифицирует следующие комментарии:\n",
    "\n",
    "- \"I have a christian friend\"\n",
    "- \"I have a muslim friend\"\n",
    "- \"I have a white friend\"\n",
    "- \"I have a black friend\"\n",
    "\n",
    "Что думаете о получившихся результатах? Есть ли у модели bias? Этичен ли он?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'I have a christian friend' - токсичность: 0.12\n",
      "'I have a muslim friend' - токсичность: 0.45\n",
      "'I have a white friend' - токсичность: 0.33\n",
      "'I have a black friend' - токсичность: 0.51\n"
     ]
    }
   ],
   "source": [
    "comments = [\n",
    "    \"I have a christian friend\",\n",
    "    \"I have a muslim friend\",\n",
    "    \"I have a white friend\",\n",
    "    \"I have a black friend\"\n",
    "          ]\n",
    "\n",
    "for comment in comments:\n",
    "    toxicity = predict_toxicity(comment, vectorizer, classifier)\n",
    "    print(f\"'{comment}' - токсичность: {toxicity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель получилась предвзято \"относится\" к мусульманам, афроамериканцам и европейцам. А вот с христинами \"всё в порядке\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 9\n",
    "\n",
    "Немного теории: в этике ИИ принято писать такой алгоритм, который будет соответствовать 4 критериям этики:\n",
    "\n",
    "1. Демографический паритет/статистический паритет. Демографический паритет говорит о том, что модель является справедливой, если состав людей, выбранных с помощью модели, соответствует проценту членства в группе претендентов.\n",
    "\n",
    "Некоммерческая организация организует международную конференцию, на участие в которой записались 20 000 человек. Организаторы пишут модель машинного обучения, чтобы отобрать 100 участников, которые потенциально могли бы выступить с интересными докладами на конференции. Поскольку 50% участников будут женщинами (10 000 из 20 000), они разрабатывают модель так, чтобы 50% выбранных кандидатов были женщинами.\n",
    "\n",
    "2. Равные возможности. Справедливость равных возможностей гарантирует, что доля людей, которые должны быть выбраны с помощью модели («позитивы»), и которые правильно выбраны с помощью модели, одинакова для каждой группы. Мы называем эту пропорцию истинно положительным показателем (TPR) или чувствительностью модели.\n",
    "\n",
    "Врач использует инструмент для выявления пациентов, нуждающихся в дополнительной помощи, которые могут подвергаться риску развития серьезных заболеваний. (Этот инструмент используется только в качестве дополнения к врачебной практике — второго мнения.) Он предназначен для обеспечения высокого TPR, одинакового для каждой демографической группы.\n",
    "\n",
    "3. Одинаковая точность. В качестве альтернативы мы могли бы проверить, имеет ли модель одинаковую точность для каждой группы. То есть процент правильных классификаций (люди, которым следует отказать, которым отказано, и люди, заявку которых следует одобрить, которых одобряют) должен быть одинаковым для каждой группы. Если модель точна на 98% для людей в одной группе, она должна быть точна на 98% для других групп.\n",
    "\n",
    "Банк использует модель для одобрения людям кредита. Модель спроектирована так, чтобы быть одинаково точной для каждой демографической группы: таким образом банк избегает одобрения людей, которым должно быть отказано (что нанесло бы финансовый ущерб как заявителю, так и банку), а также избегает отклонения людей, которые должны быть одобрены (что могло бы стать упущенной возможностью для заявителя и снизить доходы банка).\n",
    "\n",
    "4. Группа по незнанию или «справедливость через неосведомленность». Группа не осознает справедливости и удаляет всю информацию о членстве в ней из набора данных. Например, мы можем удалить гендерные данные, чтобы попытаться сделать модель справедливой для разных гендерных групп. Аналогичным образом мы можем удалить информацию о расе или возрасте.\n",
    "\n",
    "Одна из трудностей применения этого подхода на практике заключается в том, что нужно быть осторожным при идентификации и удалении прокси-серверов для данных о членстве в группах. Например, в городах, где существует расовая сегрегация, почтовый индекс является сильным показателем расы. То есть когда данные о расовой принадлежности удаляются, данные почтового индекса также должны быть удалены, иначе приложение ML все равно сможет определить расовую принадлежность человека на основе данных. Кроме того, группа, не осознающая справедливости, вряд ли станет хорошим решением проблемы исторической предвзятости.\n",
    "\n",
    "Вы заметили, что комментарии, относящиеся к исламу, с большей вероятностью будут токсичными, чем комментарии, относящиеся к другим религиям, поскольку онлайн-сообщество исламофобно. Какой тип предвзятости это может внести в вашу модель?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У модели статистическая или системная предвзятость по отношению к афроамериканцам, мусульманам и европейцам, которая, судя по всему возникает из-за использования данных слов часто в негативном контексте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 10\n",
    "\n",
    "Подумайте о том, как можно улучшить алгоритм, чтобы сделать его более этичным. Напишите 1–2 идеи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Можно заменить слова относящиеся к рассам на название вымышленой инопланетной расы, а религию на пастофарианство, чтобы избежать упоминаний о реальных религиях и рассах.\n",
    "- Можно попробовать использовать контекстные модели, такие как BERT, которые лучше понимают контекст, а не ориентируются на токсичность отдельного слова.\n",
    "- Можно попробовать сбалансировать тренировочный набор для всех рассматриваемых групп."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
